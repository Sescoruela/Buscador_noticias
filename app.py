import os
import streamlit as st
from typing import Annotated, Literal, TypedDict

from langgraph.graph.message import add_messages
from langgraph.graph import END, StateGraph
from langgraph.prebuilt import ToolNode

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, BaseMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder


# ---------------------------
# Streamlit UI
# ---------------------------
st.set_page_config(page_title="ï¿½ Â¡HOLA! Revista del CorazÃ³n", page_icon="ğŸ’•", layout="wide")

st.markdown("""
<div style='text-align: center; padding: 20px; background: linear-gradient(135deg, #ff6b9d 0%, #c06c84 100%); border-radius: 10px; margin-bottom: 20px;'>
    <h1 style='color: white; font-size: 3em; margin: 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);'>
        ğŸ’• Â¡HOLA! ğŸ’•
    </h1>
    <p style='color: white; font-size: 1.5em; margin: 10px 0 0 0; font-style: italic;'>
        Tu Revista Digital del CorazÃ³n
    </p>
    <p style='color: #ffe6f0; font-size: 1em; margin: 5px 0 0 0;'>
        âœ¨ Las noticias mÃ¡s exclusivas de tus celebridades favoritas âœ¨
    </p>
</div>
""", unsafe_allow_html=True)

with st.sidebar:
    st.markdown("### ğŸ” ConfiguraciÃ³n de RedacciÃ³n")
    google_key = st.text_input("ğŸ”‘ Gemini / Google API Key", type="password", help="Tu clave API de Google Gemini")
    tavily_key = st.text_input("ğŸ” Tavily API Key", type="password", help="Tu clave API de Tavily para bÃºsquedas")

    st.divider()
    st.markdown("### âš™ï¸ Ajustes del Editor")
    model_name = st.text_input("ğŸ¤– Modelo IA", value="gemini-2.5-flash")
    temperature = st.slider("ğŸŒ¡ï¸ Creatividad", 0.0, 1.0, 0.3, 0.05, help="Mayor valor = mÃ¡s creativo")
    max_results = st.slider("ğŸ“° Cantidad de noticias", 1, 10, 5, 1, help="NÃºmero de fuentes a consultar")

    st.divider()
    st.markdown("### ğŸ’ Secciones Populares")
    st.markdown("""
    - ğŸ’‘ **Romances y Parejas**
    - ğŸ’ **Bodas y Compromisos**
    - ğŸ‘¶ **BebÃ©s y Embarazos**
    - ğŸ’” **Rupturas y Divorcios**
    - â­ **EscÃ¡ndalos y PolÃ©micas**
    - ğŸ‘— **Moda y Glamour**
    """)
    
    st.divider()
    if st.button("ğŸ§¹ Nueva SesiÃ³n", use_container_width=True):
        st.session_state.clear()
        st.rerun()

if not google_key or not tavily_key:
    st.markdown("""
    <div style='background-color: #fff0f5; padding: 20px; border-radius: 10px; border-left: 5px solid #ff69b4;'>
        <h3 style='color: #c71585; margin-top: 0;'>ï¿½ Â¡Bienvenida/o a tu Revista del CorazÃ³n!</h3>
        <p style='color: #8b008b;'>
            Para comenzar a generar artÃ­culos exclusivos sobre tus celebridades favoritas, 
            introduce tus <strong>API Keys</strong> en la barra lateral. 
        </p>
        <p style='color: #8b008b;'>
            ğŸ’¡ <em>Â¿No tienes las claves? Consigue tu API de Google Gemini y Tavily para empezar.</em>
        </p>
    </div>
    """, unsafe_allow_html=True)
    st.stop()

# Set env vars (recomendado por integraciones)
os.environ["GOOGLE_API_KEY"] = google_key
os.environ["TAVILY_API_KEY"] = tavily_key


# ---------------------------
# LangGraph: State
# ---------------------------
class AgentState(TypedDict):
    messages: Annotated[list, add_messages]


# ---------------------------
# Prompt templates - Especializados en noticias del corazÃ³n
# ---------------------------
search_template = """Eres un experto buscador de noticias del corazÃ³n, prensa rosa y celebridades.

Tu trabajo es buscar en la web noticias relacionadas con famosos, celebridades, parejas, relaciones, escÃ¡ndalos, bodas, divorcios, 
embarazos, rumores y todo lo relacionado con el mundo del espectÃ¡culo y la prensa del corazÃ³n que sea relevante para el artÃ­culo 
que el usuario quiere generar.

IMPORTANTE: 
- Busca solo informaciÃ³n relacionada con celebridades y noticias del corazÃ³n
- NO escribas el artÃ­culo, solo busca las noticias
- EnfÃ³cate en contenido de actualidad rosa y famosos
- Pasa la informaciÃ³n al siguiente nodo para crear el esquema

NOTA: Las bÃºsquedas deben ser en espaÃ±ol cuando sea posible, o traducir el contexto al espaÃ±ol.
"""

outliner_template = """Eres un experto editor de revistas del corazÃ³n y prensa rosa.

DEBES crear un esquema estructurado y detallado para un artÃ­culo de noticias del corazÃ³n basÃ¡ndote en las noticias proporcionadas.

GENERA un esquema que incluya:

**TÃTULO PROPUESTO:** [TÃ­tulo atractivo y llamativo estilo prensa rosa]

**ESTRUCTURA DEL ARTÃCULO:**

1. **INTRODUCCIÃ“N/GANCHO:**
   - Dato mÃ¡s impactante o exclusivo que enganche al lector
   
2. **CONTEXTO DE LA HISTORIA:**
   - Antecedentes de la relaciÃ³n/situaciÃ³n
   - QuiÃ©nes son los protagonistas
   
3. **DESARROLLO:**
   - Eventos recientes y cronologÃ­a
   - Declaraciones y reacciones
   - Detalles jugosos y datos exclusivos
   
4. **REACCIÃ“N DEL PÃšBLICO:**
   - QuÃ© dicen los fans
   - Impacto en redes sociales
   
5. **CIERRE:**
   - Perspectivas a futuro
   - Pregunta o reflexiÃ³n final

**PUNTOS CLAVE A INCLUIR:** [Lista de datos especÃ­ficos, fechas, lugares, nombres]

IMPORTANTE: Genera este esquema AHORA con toda la informaciÃ³n proporcionada. NO digas que lo harÃ¡s, HAZLO.
"""

writer_template = """Eres un redactor profesional de noticias del corazÃ³n. 

ESCRIBE AHORA un artÃ­culo completo en espaÃ±ol basÃ¡ndote en el esquema proporcionado.

**INSTRUCCIONES OBLIGATORIAS:**

1. Usa este formato exacto:

TÃTULO: [TÃ­tulo atractivo]

[PÃ¡rrafo introductorio impactante]

[Desarrollo del artÃ­culo en 4-6 pÃ¡rrafos]

[Cierre emotivo]

2. ESTILO REQUERIDO:
   âœ“ Todo EN ESPAÃ‘OL
   âœ“ Tono cercano y emocionante
   âœ“ Usa expresiones de prensa rosa: "se rumorea", "fuentes cercanas revelan", "en exclusiva", "Â¡bombazo!"
   âœ“ Incluye detalles especÃ­ficos: fechas, lugares, nombres
   âœ“ Crea conexiÃ³n emocional con el lector
   âœ“ MÃ­nimo 400 palabras

3. PROHIBIDO:
   âœ— NO copies el esquema tal cual
   âœ— NO uses viÃ±etas ni listas
   âœ— NO dejes secciones vacÃ­as
   âœ— NO escribas en inglÃ©s

ESCRIBE EL ARTÃCULO COMPLETO AHORA. EMPIEZA CON "TÃTULO:" y continÃºa con el texto.
"""


def create_agent(llm, tools, system_message: str):
    """
    Crea un 'agente' como runnable:
    - Prompt con system + MessagesPlaceholder(messages)
    - Si hay tools, bind_tools(tools)
    """
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "{system_message}"),
            MessagesPlaceholder(variable_name="messages"),
        ]
    ).partial(system_message=system_message)

    if tools:
        return prompt | llm.bind_tools(tools)
    return prompt | llm


def agent_node(state: AgentState, agent, name: str):
    """
    Nodo genÃ©rico: invoca el runnable del agente con el state completo.
    Devuelve un delta de estado con un mensaje nuevo (se acumula por add_messages).
    """
    result = agent.invoke(state)  # result suele ser AIMessage
    return {"messages": [result]}


def should_search(state: AgentState) -> Literal["tools", "outliner"]:
    """
    Routing:
    - si el Ãºltimo AIMessage trae tool_calls -> "tools"
    - si no -> "outliner"
    """
    last_message = state["messages"][-1]
    if isinstance(last_message, AIMessage) and getattr(last_message, "tool_calls", None):
        if last_message.tool_calls:
            return "tools"
    return "outliner"


def build_graph(model: str, temp: float, tavily_max_results: int):
    # LLM base
    llm = ChatGoogleGenerativeAI(model=model, temperature=temp)

    # Tools (solo Tavily)
    tools = [TavilySearchResults(max_results=tavily_max_results)]
    tool_node = ToolNode(tools)

    # Agents
    search_agent = create_agent(llm, tools, search_template)
    outliner_agent = create_agent(llm, [], outliner_template)
    writer_agent = create_agent(llm, [], writer_template)

    # Nodes
    import functools
    search_node = functools.partial(agent_node, agent=search_agent, name="Search Agent")
    outliner_node = functools.partial(agent_node, agent=outliner_agent, name="Outliner Agent")
    writer_node = functools.partial(agent_node, agent=writer_agent, name="Writer Agent")

    # Graph
    workflow = StateGraph(AgentState)
    workflow.add_node("search", search_node)
    workflow.add_node("tools", tool_node)
    workflow.add_node("outliner", outliner_node)
    workflow.add_node("writer", writer_node)

    workflow.set_entry_point("search")
    workflow.add_conditional_edges("search", should_search)
    workflow.add_edge("tools", "search")
    workflow.add_edge("outliner", "writer")
    workflow.add_edge("writer", END)

    return workflow.compile()


def render_message(m: BaseMessage):
    """Render robusto para AI/Human/Tool messages."""
    if isinstance(m, HumanMessage):
        st.markdown(f"**ğŸ‘¤ Human:** {m.content}")
        return

    if isinstance(m, ToolMessage):
        st.markdown("**ğŸ§° Tool output:**")
        st.code(m.content if isinstance(m.content, str) else str(m.content))
        return

    if isinstance(m, AIMessage):
        st.markdown("**ğŸ¤– AI:**")
        # content puede ser str o lista de â€œpartsâ€
        if isinstance(m.content, str):
            st.markdown(m.content)
        elif isinstance(m.content, list):
            # intenta extraer texto
            parts = []
            for p in m.content:
                if isinstance(p, dict) and p.get("type") == "text":
                    parts.append(p.get("text", ""))
            st.markdown("\n".join([x for x in parts if x]) or str(m.content))
        else:
            st.markdown(str(m.content))

        # tool_calls (si los hay) para trazabilidad
        tc = getattr(m, "tool_calls", None)
        if tc:
            st.markdown("**ğŸ”§ Tool calls solicitadas por el modelo:**")
            st.code(str(tc))
        return

    # fallback
    st.markdown(str(m))


# ---------------------------
# Main inputs
# ---------------------------
st.markdown("""
<div style='background: linear-gradient(to right, #ffeef8, #ffe6f0); padding: 15px; border-radius: 10px; margin: 20px 0; border: 2px dashed #ff69b4;'>
    <h3 style='color: #c71585; margin-top: 0; text-align: center;'>ğŸ’« Genera tu ArtÃ­culo Exclusivo ğŸ’«</h3>
</div>
""", unsafe_allow_html=True)

col1, col2 = st.columns([3, 1], vertical_alignment="top")

with col1:
    user_instruction = st.text_area(
        "ï¿½ Â¿QuÃ© exclusiva quieres revelar?",
        value="Escribe un artÃ­culo sobre las Ãºltimas noticias de Bad Bunny y su vida amorosa. Incluye rumores recientes, declaraciones y reacciones de sus seguidores.",
        height=140,
        placeholder="Ej: La boda secreta de Shakira, el romance de RosalÃ­a, Â¿reconciliaciÃ³n a la vista?, el escÃ¡ndalo que sacude Hollywood...",
        help="Describe el tema sobre el que quieres el artÃ­culo"
    )

with col2:
    st.markdown("<br>", unsafe_allow_html=True)
    run = st.button("âœ¨ Â¡Crear Exclusiva!", type="primary", use_container_width=True)
    st.caption("ğŸ“± ArtÃ­culo generado en segundos")
    st.caption("ğŸ”¥ Con las Ãºltimas noticias")

# Persist traces
if "traces" not in st.session_state:
    st.session_state.traces = {"search": [], "tools": [], "outliner": [], "writer": []}
if "raw_updates" not in st.session_state:
    st.session_state.raw_updates = []

# ---------------------------
# Run graph + capture traces
# ---------------------------
if run:
    # reset traces for this run
    st.session_state.traces = {"search": [], "tools": [], "outliner": [], "writer": []}
    st.session_state.raw_updates = []

    graph = build_graph(model_name, temperature, max_results)

    input_message = HumanMessage(content=user_instruction)
    initial_state = {"messages": [input_message]}

    # Captura â€œpor nodoâ€ usando stream_mode="updates"
    # updates suele venir como: {"search": {"messages": [AIMessage(...)]}}
    # ToolNode aÃ±ade ToolMessage(s) en "tools"
    try:
        for update in graph.stream(initial_state, stream_mode="updates"):
            st.session_state.raw_updates.append(update)

            for node_name, partial_state in update.items():
                if node_name not in st.session_state.traces:
                    continue
                if isinstance(partial_state, dict) and "messages" in partial_state:
                    # AÃ±adimos todos los mensajes nuevos de ese nodo
                    new_msgs = partial_state["messages"]
                    if isinstance(new_msgs, list):
                        st.session_state.traces[node_name].extend(new_msgs)

    except TypeError:
        # Fallback por si tu versiÃ³n no soporta stream_mode="updates"
        # En ese caso, capturamos por "values" y volcamos todo a raw trace
        for state in graph.stream(initial_state, stream_mode="values"):
            st.session_state.raw_updates.append(state)
        st.warning("Tu versiÃ³n de LangGraph no devolviÃ³ updates por nodo. Mira la pestaÃ±a 'Raw trace'.")

# ---------------------------
# Tabs: result + trace per node
# ---------------------------
st.markdown("<br>", unsafe_allow_html=True)
tabs = st.tabs(["ğŸ’• TU EXCLUSIVA", "ğŸ” InvestigaciÃ³n", "ğŸ“° Fuentes", "ğŸ“‹ Borrador", "âœï¸ RedacciÃ³n Final", "ğŸ”§ Detalles TÃ©cnicos"])

# ArtÃ­culo final: normalmente estÃ¡ en el Ãºltimo mensaje del nodo writer
with tabs[0]:
    writer_msgs = st.session_state.traces.get("writer", [])
    if writer_msgs:
        st.markdown("""
        <div style='background: linear-gradient(135deg, #ff6b9d 0%, #c06c84 100%); padding: 20px; border-radius: 10px; margin-bottom: 20px;'>
            <h2 style='color: white; text-align: center; margin: 0;'>â­ Â¡EXCLUSIVA! â­</h2>
            <p style='color: white; text-align: center; margin: 5px 0 0 0;'>Tu artÃ­culo del corazÃ³n estÃ¡ listo</p>
        </div>
        """, unsafe_allow_html=True)
        render_message(writer_msgs[-1])
        st.markdown("---")
        st.markdown("ğŸ’ *Comparte esta exclusiva con tus amigas* ğŸ“±")
    else:
        st.markdown("""
        <div style='text-align: center; padding: 40px;'>
            <h2 style='color: #ff69b4;'>ï¿½ Â¿Lista para tu exclusiva?</h2>
            <p style='color: #c71585; font-size: 1.2em;'>
                Escribe sobre quÃ© celebridad quieres saber y haz clic en <strong>"âœ¨ Â¡Crear Exclusiva!"</strong>
            </p>
            <p style='color: #db7093;'>
                ğŸŒŸ Romances secretos â€¢ ğŸ’” Rupturas inesperadas â€¢ ğŸ’ Bodas de ensueÃ±o â€¢ ğŸ‘¶ BebÃ©s en camino
            </p>
        </div>
        """, unsafe_allow_html=True)

with tabs[1]:
    st.markdown("### ğŸ” Fase de InvestigaciÃ³n")
    st.caption("Nuestro equipo busca las Ãºltimas noticias sobre tu celebridad favorita")
    msgs = st.session_state.traces.get("search", [])
    if not msgs:
        st.info("â³ La investigaciÃ³n comenzarÃ¡ cuando solicites un artÃ­culo...")
    else:
        for i, m in enumerate(msgs, start=1):
            st.markdown(f"---\n#### ğŸ” InvestigaciÃ³n #{i}")
            render_message(m)

with tabs[2]:
    st.markdown("### ğŸ“° Fuentes y Referencias")
    st.caption("ArtÃ­culos y noticias consultadas de medios especializados")
    msgs = st.session_state.traces.get("tools", [])
    if not msgs:
        st.info("ğŸ“š Las fuentes aparecerÃ¡n aquÃ­ durante la investigaciÃ³n...")
    else:
        for i, m in enumerate(msgs, start=1):
            st.markdown(f"---\n#### ğŸ“„ Fuente #{i}")
            render_message(m)

with tabs[3]:
    st.markdown("### ğŸ“‹ Borrador y Estructura")
    st.caption("El esquema preliminar de tu artÃ­culo exclusivo")
    msgs = st.session_state.traces.get("outliner", [])
    if not msgs:
        st.info("âœï¸ El borrador se crearÃ¡ despuÃ©s de recopilar las noticias...")
    else:
        for i, m in enumerate(msgs, start=1):
            st.markdown(f"---\n#### ğŸ“ Esquema #{i}")
            render_message(m)

with tabs[4]:
    st.markdown("### âœï¸ RedacciÃ³n Final")
    st.caption("El artÃ­culo completo siendo elaborado por nuestros redactores")
    msgs = st.session_state.traces.get("writer", [])
    if not msgs:
        st.info("ğŸ“ƒ La redacciÃ³n comenzarÃ¡ una vez terminado el borrador...")
    else:
        for i, m in enumerate(msgs, start=1):
            st.markdown(f"---\n#### âœ¨ VersiÃ³n #{i}")
            render_message(m)

with tabs[5]:
    st.markdown("### ğŸ”§ InformaciÃ³n TÃ©cnica")
    st.caption("Detalles del proceso de generaciÃ³n (para desarrolladores)")
    if not st.session_state.raw_updates:
        st.info("âš™ï¸ Los detalles tÃ©cnicos aparecerÃ¡n durante el proceso...")
    else:
        with st.expander("ğŸ“Š Ver trazas completas"):
            st.code(str(st.session_state.raw_updates[:50]))
            if len(st.session_state.raw_updates) > 50:
                st.caption(f"Mostrando 50 de {len(st.session_state.raw_updates)} entradas tÃ©cnicas.")
